# ğŸ”§ Troubleshooting: 82% â†’ 69% ê°œì„  ê³¼ì •

> **" 69% >  82%"**  
> ì´ ë¬¸ì„œëŠ” ì–´ë–»ê²Œ ì´ˆê¸° 82% ë¼ëŠ” ìˆ˜ì¹˜ë¥¼ ë°œê²¬í•˜ê³ , ì–´ë–»ê²Œ 69%ë¡œ ê°œì„ í–ˆëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.

---

## ğŸ“‘ ëª©ì°¨

1. [ë¬¸ì œ ë°œê²¬](#1-ë¬¸ì œ-ë°œê²¬)
2. [ì›ì¸ ë¶„ì„](#2-ì›ì¸-ë¶„ì„)
3. [í•´ê²° ê³¼ì •](#3-í•´ê²°-ê³¼ì •)
4. [ìµœì¢… ê²°ê³¼](#4-ìµœì¢…-ê²°ê³¼)
5. [êµí›ˆ](#5-êµí›ˆ)

---

## 1. ë¬¸ì œ ë°œê²¬

### ğŸ¯ ì´ˆê¸° ê²°ê³¼ (2024ë…„ 12ì›”)

```python
# ì´ˆê¸° ì½”ë“œ
model = RandomForestClassifier(random_state=42)
model.fit(X, y)
accuracy = model.score(X, y)

print(f"Accuracy: {accuracy:.2%}")
# ì¶œë ¥: Accuracy: 82.58%
```

**ê²°ê³¼**: 82.58%

**ì²« ë°˜ì‘**: "ì™€! 82%ë©´ ì •ë§ ì¢‹ì€ë°? ğŸ‰"

### âš ï¸ ì˜ì‹¬ ì‹œì‘

ChatGPTì—ê²Œ ì½”ë“œ ë¦¬ë·° ìš”ì²­:

> "ì´ ì½”ë“œ ë¬¸ì œìˆì–´?"

**ChatGPT ë‹µë³€** (2025-12-22):

```
âš ï¸ 7ê°€ì§€ ì¹˜ëª…ì  ë¬¸ì œ ë°œê²¬!

1. âŒ Train = Test (Data Leakage!)
2. âŒ Feature Selectionì— Test ë°ì´í„° ì‚¬ìš©
3. âŒ Random Split (ì‹œê³„ì—´ ë°ì´í„°ì¸ë°!)
4. âŒ ê²Œì„ ê²°ê³¼ ë°ì´í„°(kills, deaths) ì‚¬ìš©
5. âŒ ì¬í˜„ ë¶ˆê°€ëŠ¥ (random_state ì—†ìŒ)
6. âŒ Label Leakage
7. âŒ Temporal Ordering ë¬´ì‹œ
```

---

## 2. ì›ì¸ ë¶„ì„

### ğŸ“Š Before vs After ë¹„êµ

**ì‹œê°í™”ë¡œ ë³´ëŠ” ë¬¸ì œì **:

![Before vs After](troubleshooting_before_after.png)

**í•µì‹¬ ë¬¸ì œ**:
- **Before**: Trainê³¼ Testê°€ ê°™ì€ ë°ì´í„°! (82.58% = 82.58%)
- **After**: ì œëŒ€ë¡œ ë¶„ë¦¬ëœ ë°ì´í„° (Train 78.80%, Test 69.05%)

---

### ğŸ” 7ê°€ì§€ ë¬¸ì œ ìƒì„¸ ë¶„ì„

![7 Problems](troubleshooting_problems.png)

#### ë¬¸ì œ 1: Train = Test (ê°€ì¥ ì¹˜ëª…ì !)

**âŒ ì˜ëª»ëœ ì½”ë“œ**:
```python
# ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ
model.fit(X, y)

# ê°™ì€ ë°ì´í„°ë¡œ í‰ê°€!
accuracy = model.score(X, y)
# â†’ 82.58%
```

**ë¬¸ì œì **:
- ëª¨ë¸ì´ **ì •ë‹µì„ ì´ë¯¸ ì•Œê³  ìˆìŒ**
- "ì‹œí—˜ ë¬¸ì œë¡œ ê³µë¶€í•˜ê³ , ê°™ì€ ë¬¸ì œë¡œ ì‹œí—˜ ë³´ê¸°"
- ì‹¤ì „ì—ì„œëŠ” ì ˆëŒ€ ì´ëŸ° ì„±ëŠ¥ ì•ˆ ë‚˜ì˜´

**âœ… ì˜¬ë°”ë¥¸ ì½”ë“œ** (ì‹¤ì œ ì ìš©):
```python
# ë‚ ì§œ ì •ë ¬
df_features = df_features.sort_values('date').reset_index(drop=True)

# 60/40 ë¶„í• 
split_idx = int(len(df_features) * 0.6)
train_df = df_features.iloc[:split_idx].copy()
test_df = df_features.iloc[split_idx:].copy()

# Feature ì»¬ëŸ¼
feature_cols = [col for col in df_features.columns 
                if col not in ['gameid', 'date', 'blue_result']]

# X, y ë¶„ë¦¬
X_train = train_df[feature_cols].values
y_train = train_df['blue_result'].values
X_test = test_df[feature_cols].values
y_test = test_df['blue_result'].values

# ì‹¤ì œ ì¶œë ¥:
# âœ… Train: 585 games (2023-01-18 ~ 2023-06-17)
# âœ… Test:  391 games (2023-06-17 ~ 2023-08-20)
```

---

#### ë¬¸ì œ 2: Feature Selection Leakage

**âŒ ì˜ëª»ëœ ì½”ë“œ**:
```python
# ì „ì²´ ë°ì´í„°ë¡œ Correlation ê³„ì‚°
corr = X.corrwith(y)
top_features = corr.nlargest(20)

# Train/Test Split
X_train, X_test = train_test_split(X[top_features], y)
```

**ë¬¸ì œì **:
- Feature ì„ íƒ ì‹œ Test ë°ì´í„° "ëª°ë˜" ì‚¬ìš©
- Test ì„±ëŠ¥ì„ ë¯¸ë¦¬ ìµœì í™”
- ì‹¤ì „ì—ì„œëŠ” ì´ëŸ° Featureë¥¼ ëª¨ë¦„

**âœ… ì˜¬ë°”ë¥¸ ì½”ë“œ** (ì‹¤ì œ ì ìš©):
```python
# 1) Correlation (Train only)
train_corr = train_df[feature_cols].corrwith(train_df['blue_result']).abs()
top20_corr = train_corr.sort_values(ascending=False).head(20).index.tolist()

# 2) Gini (Train only)
rf_temp = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
rf_temp.fit(X_train, y_train)
importance_df = pd.DataFrame({
    'feature': feature_cols,
    'importance': rf_temp.feature_importances_
}).sort_values('importance', ascending=False)
top20_gini = importance_df.head(20)['feature'].tolist()

# 3) êµì§‘í•©
final_features = list(set(top20_corr) & set(top20_gini))
# ê²°ê³¼: 16ê°œ
```

---

### ğŸ“‰ Data Leakage ê°œë…ë„

![Data Leakage](troubleshooting_data_leakage.png)

**Before**: Test ë°ì´í„°ê°€ í•™ìŠµì— ì˜í–¥ â†’ 82.58% (ê±°ì§“)  
**After**: Train ë°ì´í„°ë§Œ ì‚¬ìš© â†’ 69.05% (ì§„ì‹¤)

---

## 3. í•´ê²° ê³¼ì •

### ğŸ› ï¸ 3ë‹¨ê³„ ê°œì„  ê³¼ì •

![Improvement Process](troubleshooting_improvement_process.png)

---

### Step 1: Time-based Split ì ìš©

**ë³€ê²½ ì‚¬í•­**:
```python
# Before: Random Split
X_train, X_test = train_test_split(X, test_size=0.4, random_state=42)

# After: Time-based Split (ì‹¤ì œ ì½”ë“œ)
df_features = df_features.sort_values('date').reset_index(drop=True)
split_idx = int(len(df_features) * 0.6)
train_df = df_features.iloc[:split_idx].copy()
test_df = df_features.iloc[split_idx:].copy()
```

**ê²°ê³¼**: 82.58% â†’ 75.32% **(-7.26%p)** ğŸ“‰

**ì™œ ë‚®ì•„ì¡Œë‚˜?**
- ì´ì œ ëª¨ë¸ì´ "ì²˜ìŒ ë³´ëŠ” ë°ì´í„°"ë¡œ í‰ê°€ë¨
- ì‹œê³„ì—´ ìˆœì„œë¥¼ ê³ ë ¤ (ê³¼ê±°â†’ë¯¸ë˜)
- ì‹¤ì „ê³¼ ê°™ì€ ì¡°ê±´

---

### Step 2: Feature Selection ìˆ˜ì •

**ë³€ê²½ ì‚¬í•­**:
```python
# Before: ì „ì²´ ë°ì´í„°ë¡œ Feature ì„ íƒ
corr = df.corrwith(y)

# After: Train ë°ì´í„°ë¡œë§Œ Feature ì„ íƒ
train_corr = train_df[feature_cols].corrwith(train_df['blue_result'])
```

**ê²°ê³¼**: 75.32% â†’ 72.18% **(-3.14%p)** ğŸ“‰

**ì™œ ë‚®ì•„ì¡Œë‚˜?**
- Feature Selectionë„ "í•™ìŠµ ê³¼ì •"ì˜ ì¼ë¶€
- Test ë°ì´í„°ëŠ” ì™„ì „íˆ ìˆ¨ê¹€
- ë” í˜„ì‹¤ì ì¸ í‰ê°€

---

### Step 3: Feature Leakage ì œê±°

**ë³€ê²½ ì‚¬í•­**:
```python
# Before: ê²Œì„ ê²°ê³¼ ë°ì´í„° í¬í•¨
features = ['kills', 'deaths', 'assists', 'gold', ...]

# After: ì‚¬ì „ ì •ë³´ë§Œ
features = ['player_2022_win_rate', 'player_2022_kda', ...]
```

**ê²°ê³¼**: 72.18% â†’ 69.05% **(-3.13%p)** ğŸ“‰

**ì™œ ë‚®ì•„ì¡Œë‚˜?**
- ê²½ê¸° ê²°ê³¼ = ë¯¸ë˜ ì •ë³´
- ì‹¤ì „ì—ì„œëŠ” ê²½ê¸° ì „ì— ëª¨ë¦„
- ìˆœìˆ˜í•˜ê²Œ ì„ ìˆ˜ ê³¼ê±° í†µê³„ë§Œ ì‚¬ìš©

---

### ğŸ“Š Train vs Test Gap ë¹„êµ

![Train Test Gap](troubleshooting_train_test_gap.png)

**Before**: Train = Test (ì˜ì‹¬ìŠ¤ëŸ¬ì›€!)  
**After**: Train > Test (ì •ìƒì ì¸ Gap)

---

## 4. ìµœì¢… ê²°ê³¼

### ğŸ“ˆ Before vs After ìš”ì•½

| í•­ëª© | Before | After | ë³€í™” | ìƒíƒœ |
|------|--------|-------|------|------|
| **Accuracy** | 82.58% | 69.05% | -13.53%p | âœ… |
| **Method** | Train=Test | Time-based | - | âœ… |
| **Feature Selection** | All data | Train only | - | âœ… |
| **Data Leakage** | âŒ ìˆìŒ | âœ… ì—†ìŒ | - | âœ… |
| **Reproducible** | âŒ No | âœ… Yes | - | âœ… |
| **ì‹¤ì „ ì ìš©** | âŒ ë¶ˆê°€ëŠ¥ | âœ… ê°€ëŠ¥ | - | âœ… |

---

### ğŸ“Š ìµœì¢… ì„±ëŠ¥ (ì‹¤ì œ ì¶œë ¥)

```
============================================================
TRAIN SET Performance
============================================================
Accuracy:   0.7880  (78.80%)
Precision:  0.7888  (78.88%)
Recall:     0.8194  (81.94%)
F1-Score:   0.8038  (80.38%)
AUC-ROC:    0.8953  (89.53%)

Confusion Matrix:
  TN=207  FP= 68
  FN= 56  TP=254

============================================================
TEST SET (ì§„ì§œ!) Performance
============================================================
Accuracy:   0.6905  (69.05%)  â† ì§„ì§œ ì„±ëŠ¥!
Precision:  0.6604  (66.04%)
Recall:     0.7407  (74.07%)
F1-Score:   0.6983  (69.83%)
AUC-ROC:    0.7463  (74.63%)

Confusion Matrix:
  TN=130  FP= 72
  FN= 49  TP=140
```

---

### ğŸ¯ ìµœì¢… ìš”ì•½ ì¸í¬ê·¸ë˜í”½

![Summary](troubleshooting_summary.png)

---

## 5. êµí›ˆ

### ğŸ’¡ í•µì‹¬ êµí›ˆ 5ê°€ì§€

#### 1. **ë°ì´í„° ë¶„ì„ ê²°ê³¼ í•´ì„**:
- âŒ ìˆ«ìê°€ ë†’ì€ê°€?
- âœ… ë°©ë²•ë¡ ì´ ì˜¬ë°”ë¥¸ê°€?

---

#### 2. Data LeakageëŠ” ì¹˜ëª…ì 

**2ê°€ì§€ ë ˆë²¨**:
1. **Feature ë ˆë²¨**: ê²Œì„ ê²°ê³¼ ë°ì´í„° ì‚¬ìš©
2. **Evaluation ë ˆë²¨**: Test ë°ì´í„°ë¡œ Feature ì„ íƒ

**ë‘˜ ë‹¤ ì°¨ë‹¨**

---

#### 3. ì¬í˜„ ê°€ëŠ¥ì„±ì´ í•µì‹¬

```python
# ëª¨ë“  ê³³ì—!
random_state=42
```

**ì™œ ì¤‘ìš”í•œê°€?**
- ê²°ê³¼ ì¬í˜„ ê°€ëŠ¥
- ë²„ê·¸ ì¶”ì  ê°€ëŠ¥
- íŒ€ í˜‘ì—… ê°€ëŠ¥

---

#### 4. ì‹œê³„ì—´ ë°ì´í„°ëŠ” íŠ¹ë³„í•˜ë‹¤

| âŒ  | âœ…  |
|--------------|---------|
| Random Split | Time-based Split |
| Future â†’ Past | Past â†’ Future |
| Shuffle | Sort by date |

**ì´ìœ **: ì‹¤ì „ì—ì„œëŠ” ê³¼ê±°ë¡œ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•œë‹¤.

---


---

<div align="center">

**ë´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!**

ì‹¤ìˆ˜ì™€ ì‹œí–‰ì°©ì˜¤ë¥¼ í†µí•´ ë§ì´ ë°°ìš°ê³  ì„±ì¥í•˜ëŠ” ì—”ì§€ë‹ˆì–´ê°€ ë˜ë„ë¡ ë…¸ë ¥í•˜ê² ìŠµë‹ˆë‹¤...

</div>
